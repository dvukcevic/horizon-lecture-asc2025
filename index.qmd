---
title: "You May Peek at Your Data"
subtitle: "Modern sequential inference, applied to election auditing"
institute: "Horizon Lecture, Australian Statistical Conference 2025"
date: "1 December 2025"
date-format: "D MMMM YYYY"
author: "Damjan Vukcevic"
format:
  presentation-revealjs+letterbox:
    from: markdown+emoji
    self-contained: false
    #self-contained: true
    #self-contained-math: true
    title-slide-attributes:
      data-background-image: "images/bg-07.png"
---

# We love to peek

## Peeking :eye:

Planned study: 200 participants

. . .

After **40 participants**, you decide to do an interim analysis :eye::

. . .

-   Large effect estimate
-   p-value = **0.03** :warning:
-   *"Do we really need more data?"*

. . .

Could also have checked at 40, 80, 120, 160 participants.

. . .

High probability of *accidentally* seeing p \< 0.05 at least once.

## P-hacking :dart:

Planned study: 200 participants

. . .

After 200 participants, you do the analysis:

-   Effect in the right direction
-   p-value = **0.08** :confused:
-   *"So close...let's add 20 more participants."*

. . .

After 20 more: p = **0.06**\
And another 20 more: p = **0.049** :dart: → publish!

. . .

Similar to peeking, large chance of seeing p \< 0.05.

## What we teach :mortar_board:

-   Choose a fixed sample size
-   Perform one pre-specified analysis
-   CIs & hypothesis tests nicely calibrated
-   **Don't peek!**

. . .

Statistical "abstinence"

## In the real world :parasol_on_ground:

Abstinence is brittle...

. . .

-   We check results early
-   Data might trickle in slowly
-   We adjust analysis plans
-   We stop some experiments early
-   We continue more promising ones longer

## A more liberal approach

Can we design statistical methods that\
**remain valid** even if we analyse the data\
**whenever we like**?

# Sequential analysis

## Sequential probability ratio test (SPRT)

::::: columns
::: {.column width="40%"}
<!-- https://en.wikipedia.org/wiki/File:Abraham_Wald_in_his_youth.jpg -->

![](images/Abraham_Wald_in_his_youth.jpg){width="80%"}
:::

::: {.column width="60%"}
Developed by [Wald (1945)](#references)

Birth of sequential analysis
:::
:::::

## Binary data example

::::: columns
::: {.column width="70%"}
Data ($X_i$): $$0, 0, 1, 1, 0, 1, \dots$$

Hypotheses: $$\begin{cases}
    H_0\colon p = p_0 \\
    H_1\colon p = p_1
    \end{cases}$$
:::

::: {.column width="30%"}
<!-- https://www.wannapik.com/vectors/3720 -->

![](images/coin_flip_smaller.png)
:::
:::::

## Binary data example

Test statistic: $$S_t = \frac{L_t(p_1)}{L_t(p_0)}
          = \frac{\Pr(X_1, \dots, X_t \mid H_1)}
                 {\Pr(X_1, \dots, X_t \mid H_0)}
          = \frac{p_1^{Y_t} (1 - p_1)^{t - Y_t}}
                 {p_0^{Y_t} (1 - p_0)^{t - Y_t}}$$

Where: $Y_t = \sum_{i=1}^t X_i$

## Binary data example

```{r}
#| label: sprt-simulation

set.seed(1596)

# Set parameters.
p_true <- 0.6  # true proportions
n <- 50        # maximum sample size

# SPRT settings.
p0 <- 0.5   # null hypothesis
p1 <- 0.7   # alternative hypothesis
a <- 0.1    # type I error
b <- 0.1    # type II error
bounds <- c(b / (1 - a), (1 - b) / a)

# Simulate data.
x <- rbinom(n, 1, p_true)
y <- cumsum(x)
ns <- 1:n
s <- p1^y * (1 - p1)^(ns - y) / (p0^y * (1 - p0)^(ns - y))
p.hat <- y / ns
```

```{r}
#| label: sprt-binary-example-statistic
#| fig-width: 6
#| fig-height: 4

par(mar = c(5, 5, 2, 5))
plot(ns, s, type = "n", las = 1,
     xlim = c(0, n + 10),
     ylim = range(0, bounds),
     xlab = expression("Sample size, " * t),
     ylab = expression("Test statistic, " * S[t]))
grid()
#abline(h = 1, lty = 3, lwd = 1.5, col = "skyblue")
#axis(2, at = 1, las = 1)
lines(ns, s, lwd = 2, col = "blue")
points(tail(ns, 1), tail(s, 1), pch = 19, cex = 1.5, col = "blue")
```

## Binary data example

Stopping rule: $$\begin{cases}
    S_t \leqslant \frac{\beta}{1 - \alpha} & \Rightarrow \text{accept } H_0 \\
    S_t \geqslant \frac{1 - \beta}{\alpha} & \Rightarrow \text{accept } H_1 \\
    \text{otherwise} & \Rightarrow \text{keep sampling}
    \end{cases}$$

. . .

Error control:

-   Type 1 error $\leqslant \alpha$
-   Type 2 error $\leqslant \beta$

## Binary data example

```{r}
#| label: sprt-binary-example-statistic-with-bounds
#| fig-width: 6
#| fig-height: 4

par(mar = c(5, 5, 2, 5))
plot(ns, s, type = "n", las = 1,
     xlim = c(0, n + 10),
     ylim = range(0, bounds),
     xlab = expression("Sample size, " * t),
     ylab = expression("Test statistic, " * S[t]))
grid()
lines(ns, s, lwd = 2, col = "blue")
abline(h = bounds, lty = 2, lwd = 1, col = "magenta")
points(tail(ns, 1), tail(s, 1), pch = 19, cex = 1.5, col = "blue")
axis(4, at = bounds, expression(frac(beta, (1 - alpha)), frac((1 - beta), alpha)),
     las = 1, col.axis = "magenta")
```

## Sample size distribution

```{r}
#| label: sprt-sample-size-calculations

# Function to simulate one SPRT run.
simulate_sprt <- function(true_p) {
  logLR <- 0
  n <- 0
  
  repeat {
    x <- rbinom(1, 1, true_p)
    n <- n + 1
    
    # Update log-likelihood ratio.
    logLR <- logLR + log(p1 / p0) * x + log((1 - p1)/(1 - p0)) * (1 - x)
    
    # Check stopping conditions.
    if (logLR >= log(bounds[2])) return(n)  # accept H1
    if (logLR <= log(bounds[1])) return(n)  # accept H0
  }
}

# Simulate sample sizes
set.seed(33)
Nsim <- 1e4

#sample_sizes_p0 <- replicate(Nsim, simulate_sprt(p0))
sample_sizes_p1 <- replicate(Nsim, simulate_sprt(p1))

# Sample size for a corresponding fixed-sample size test.
#
# Testing:
#    H0: p = p0
#    H1: p > p0
#
# With a given significance level (a) and power (1 - b) at p = p1.
fixed_n_one_sided <- function() {
  stopifnot(p1 > p0)
  
  z_alpha <- qnorm(1 - a)  # critical value for one-sided test
  z_beta  <- qnorm(1 - b)  # power = Pr(reject | p = p1)
  
  # Normal approximation sample size formula.
  n <- ((z_alpha * sqrt(p0 * (1 - p0)) +
         z_beta  * sqrt(p1 * (1 - p1)))^2) / (p1 - p0)^2
  
  return(ceiling(n))
}
n_fixed <- fixed_n_one_sided()
```

```{r}
#| label: sprt-sample-size-stats
#| eval: false
#| include: false
summary(sample_sizes_p0)
summary(sample_sizes_p1)
mean(sample_sizes_p0 < n_fixed)
mean(sample_sizes_p1 < n_fixed)
```

::::: columns
::: {.column width="60%"}
```{r}
#| label: sprt-sample-size
#| fig-width: 5
#| fig-height: 4
#| out-width: "100%"

# Plot the empirical distribution.
par(mar = c(5, 4, 0, 0))
hist(sample_sizes_p1,
     breaks = 50,
     probability = TRUE,
     main = "",
     xlab = "Sample size at stopping",
     las = 1,
     col = "lightblue",
     border = "white")
grid()
abline(v = n_fixed, lwd = 2, col = "magenta")
```
:::

::: {.column width="40%"}
-   Parameters:

    -   $p_0 = 0.5$
    -   $p_1 = 0.7 = p$
    -   $\alpha = \beta = 0.1$

-   $n = 38$ for fixed-$n$ test with same power

-   SPRT often stops earlier
:::
:::::

## 

::::: columns
::: {.column width="50%"}
### Benefits :thumbsup:

-   Safe: can "peek"
-   Efficient: small sample sizes
-   Can "accept" $H_0$
-   Principled “no decision” is possible
:::

::: {.column width="50%"}
### Disadvantages :thumbsdown:

-   Operational planning more complex
-   Sample size unknown in advance
-   Sample size could be very large
-   Only simple vs simple (for now...)
:::
:::::

## SPRT in general

$$H_0\colon X \sim f_0(\cdot) \quad \text{vs} \quad
  H_1\colon X \sim f_1(\cdot)$$

Test statistic: $$S_t = \frac{f_1(X_1, X_2, \dots, X_t)}
                 {f_0(X_1, X_2, \dots, X_t)}$$

Test statistic, with iid observations:
$$S_t = \prod_{i=1}^t \frac{f_1(X_i)}{f_0(X_i)}
          = S_{t - 1} \times \frac{f_1(X_t)}{f_0(X_t)}$$

## "Tests of power one"

::::: columns
::: {.column width="45%"}
-   Set $\beta = 0$
-   Stopping rule:\
    Reject $H_0$ once $S_t \geqslant 1 / \alpha$
-   Never "accept" $H_0$
-   No type II error (power = 1), but might have $n = \infty$.
:::

::: {.column width="55%"}
```{r}
#| label: sprt-single-boundary
#| fig-width: 5
#| fig-height: 3.5
#| out-width: "100%"

# New boundary.
bound1 <- 1 / a

# Draw plot.
par(mar = c(4, 4, 1, 2))
plot(ns, s, type = "n", las = 1,
     ylim = range(0, bound1 + 1),
     xlim = c(0, 80),
     xlab = expression("Sample size, " * t),
     ylab = expression("Test statistic, " * S[t]))
grid()
lines(ns, s, lwd = 2, col = "blue")
abline(h = bound1, lty = 2, lwd = 1, col = "magenta")
points(tail(ns, 1), tail(s, 1), pch = 19, cex = 1.5, col = "blue")
axis(2, at = 1, las = 1)
axis(4, at = bound1, expression(frac(1, alpha)),
     las = 1, col.axis = "magenta")
```
:::
:::::

# What makes sequential inference "safe"?

##  {.full}

```{r}
#| label: martingales-simulation

set.seed(142)

# Set parameters.
n <- 12  # maximum sample size

# Simulate data.
x0 <- rbinom(n, 1, p0)
x1 <- rbinom(n, 1, p0 * 0.9)
x2 <- rbinom(n, 1, p1)
y0 <- cumsum(x0)
y1 <- cumsum(x1)
y2 <- cumsum(x2)
ns <- 1:n
s0 <- p1^y0 * (1 - p1)^(ns - y0) / (p0^y0 * (1 - p0)^(ns - y0))
s1 <- p1^y1 * (1 - p1)^(ns - y1) / (p0^y1 * (1 - p0)^(ns - y1))
s2 <- p1^y2 * (1 - p1)^(ns - y2) / (p0^y2 * (1 - p0)^(ns - y2))
```

```{r}
#| label: plot-martingales-setup

# Function to draw arrows coming out of a point.
draw_arrows <- function(
  x0 = 0, y0 = 0,
  angles = c(-20, 0, 20),
  length = c(2, 2.5, 2),
  col = "grey40",
  lwd = 1
) {
  # Compute endpoints.
  x1 <- x0 + length * cos(angles * pi/180)
  y1 <- y0 + length * sin(angles * pi/180)
  
  # Draw arrows.
  for (i in seq_along(angles)) {
    arrows(x0, y0, x1[i], y1[i],
           length = 0.1, col = col, lwd = lwd)
  }
  
  # Draw starting point.
  points(x0, y0, pch = 19, cex = 1.5, col = "blue")
}
```

::::: columns
::: {.column width="50%"}
### Martingale

```{r}
#| label: plot-martingale
#| fig-width: 5
#| fig-height: 3.5
#| out-width: "100%"

par(mar = c(4, 3, 1, 1))

plot(ns, s0, type = "n", las = 1,
     xlim = c(0, n + 8),
     ylim = range(0, s0),
     xlab = expression(t),
     ylab = "")
grid()
lines(ns, s0, lwd = 2, col = "blue")
draw_arrows(tail(ns, 1), tail(s0, 1))
```

"Stays the same" on average
:::

::: {.column width="50%"}
### Supermartingale :superhero:

```{r}
#| label: plot-supermartingale
#| fig-width: 5
#| fig-height: 3.5
#| out-width: "100%"

par(mar = c(4, 3, 1, 1))

plot(ns, s1, type = "n", las = 1,
     xlim = c(0, n + 8),
     ylim = range(0, s1),
     xlab = expression(t),
     ylab = "")
grid()
lines(ns, s1, lwd = 2, col = "blue")
draw_arrows(tail(ns, 1), tail(s1, 1),
            angles = c(-10, -5, 0, 5),
            length = 1.5)
```

"Stays the same or reduces in value" on average
:::
:::::

## Ville's inequality

Let $S_0, S_1, S_2, \dots$ be a **test supermartingale** (TSM):\
has non-negative terms ($S_i \geqslant 0$) and starting value $S_0 = 1$.

. . .

For any $\alpha > 0$,
$$\Pr\left(\max_t (S_t) \geqslant \frac{1}{\alpha}\right) \leqslant \alpha$$

## Tests based on martingales

-   $S_t$ should be a **test supermartingale** (TSM) under $H_0$
-   $S_t$ should **grow quickly** under $H_1$

::::: columns
::: {.column width="50%"}
```{r}
#| label: plot-process-h0
#| fig-width: 5
#| fig-height: 3.5
#| out-width: "100%"

par(mar = c(4, 4.5, 2, 1))

plot(ns, s1, type = "n", las = 1,
     xlim = c(0, n + 3),
     ylim = range(0, s1, s2 + 0.5),
     main = expression(S[t] * " under " * H[0]),
     xlab = expression(t),
     ylab = expression("Test statistic, " * S[t]))
grid()
lines(c(0, ns), c(1, s1), lwd = 2, col = "blue")
points(tail(ns, 1), tail(s1, 1), pch = 19, cex = 1.5, col = "blue")
```
:::

::: {.column width="50%"}
```{r}
#| label: plot-process-h1
#| fig-width: 5
#| fig-height: 3.5
#| out-width: "100%"

par(mar = c(4, 4.5, 2, 1))

plot(ns, s2, type = "n", las = 1,
     xlim = c(0, n + 3),
     ylim = range(0, s1, s2 + 0.5),
     main = expression(S[t] * " under " * H[1]),
     xlab = expression(t),
     ylab = expression("Test statistic, " * S[t]))
grid()
lines(c(0, ns), c(1, s2), lwd = 2, col = "blue")
points(tail(ns, 1), tail(s2, 1), pch = 19, cex = 1.5, col = "blue")
```
:::
:::::

## Beyond simple hypotheses

$$H_0\colon \theta = \theta_0 \quad \text{vs} \quad
  H_1\colon \theta \in \mathcal{A}$$

. . .

Plug-in strategy:
$$S_t = S_{t-1} \times \frac{f(X_t \mid \hat\theta_t)}{f(X_t \mid \theta_0)}$$
$$\hat\theta_t = a(X_1, X_2, \dots, X_{t-1}) \in \mathcal{A}$$

## Beyond simple hypotheses

$$H_0\colon \theta = \theta_0 \quad \text{vs} \quad
  H_1\colon \theta \in \mathcal{A}$$

Mixture strategy:
$$S_t = S_{t-1} \times \frac{\int_{\mathcal{A}} f(X_t \mid \theta) \, g_t(\theta) \, d\theta}{f(X_t \mid \theta_0)}$$
$$g_t(\theta) \text{ is a distribution over } \mathcal{A}$$
$$g_t(\theta) \text{ can depend on } X_1, X_2, \dots, X_{t-1}$$

## Safe inference

SAVI: "safe, anytime-valid inference"

-   Stopping rules :stop_button: may depend on the data
-   *Optional stopping* :eye: permitted
-   *Optional continuation* :dart: permitted

. . .

Anytime-valid CIs, p-values and test decisions.

. . .

Review paper: [Ramdas et al. (2023)](#references)

# Election auditing

## Acknowledgements :heart_decoration:

::::: columns
::: {.column width="50%"}
-   Michelle Blom
-   Alexander Ek
-   Floyd Everest
-   Dania Freidgeim
:::

::: {.column width="50%"}
-   Dennis Leung
-   Philip Stark
-   Peter Stuckey
-   Vanessa Teague
:::
:::::

. . .

Australian Research Council:

-   Discovery Project DP22010101
-   OPTIMA ITTC IC200100009

## Counting the votes

![](images/AEC-HoR-election-night-opening.jpg)

## Counting the votes

![](images/AEC-HoR-counting-1.jpg)

## Counting the votes

![](images/AEC-Centralised-Senate-Scrutiny-papers-1.jpg)

## What can go wrong?

-   Human error
-   Machine malfunction
-   Malicious interference

. . .

More automation $\rightarrow$ less scrutiny

## Election audits

Goal:

-   Detect (and correct) wrong election outcomes

. . .

Gold standard:

-   Full hand count of paper ballots
-   Slow & expensive

. . .

Alternative: **statistics!** :bar_chart:

-   Sample ballot papers, infer the winners
-   Fast & cheap -- via sequential tests

## Two-candidate example

Election: **Albo** vs Dutton :wrestling:

. . .

$p = \text{Proportion of votes for Albo}$

. . .

$$\begin{cases}
H_0\colon p \leqslant 0.5, & \text{Albo did not win} \\
H_1\colon p  >        0.5, & \text{Albo won}
\end{cases}$$

## Two-candidate example

SPRT with a plug-in estimator of $p$:

$$S_t = S_{t-1} \times \frac{\Pr(X_t \mid \hat{p}_t)}{\Pr(X_t \mid p = 0.5)}$$
$$\hat{p}_t = h(X_1, \dots, X_{t-1}) \in (0.5, 1]$$

. . .

"ALPHA supermartingale" ([Stark 2023](#references))

## Preferential elections

![](images/irv-ballot-small.png)

## Voting

**Rank** the candidates in order of preference.

Examples:

-   \(1\) Lynne, (2) Ben, (3) Ian

-   \(1\) Ben, (2) Lynne, (3) Ian

-   \(1\) Ian, (2) Lynne

-   \(1\) Ben

## Counting

Iterative algorithm:

-   Eliminate least preferred candidate; redistribute their votes
-   Last candidate standing is the winner.

. . .

This produces an **elimination order**.

Example:

-   \[Ian, Ben, **Lynne**\]

## Auditing challenge

$H_0$ includes all **elimination orders** with\
**alternative winners** ("alt-orders").

. . .

$k$ candidates $\Rightarrow$ $\sim k!$ ballot types\
$k$ candidates $\Rightarrow$ $\sim k!$ alt-orders

. . .

Challenges:

-   High-dimensional parameter space
-   Complex boundary between $H_0$ and $H_1$

## Auditing strategy

1.  Decompose $H_0$ into simpler, 1-dimensional statements
2.  Test each statement separately
3.  Combine test results into a single decision

## Simple statements

Example:

> "Lynne has more votes than Ben assuming that only\
> candidates in the set $\mathcal{S}$ remain standing."

. . .

Equivalent to a two-candidate election.

Can test using ALPHA.

## Hypothesis decompositions

Unions: $$H = H^1 \cup H^2 \cup \dots \cup H^m$$
$$\text{Reject every } H^j \Rightarrow \text{Reject } H$$

. . .

Intersections: $$H = H^1 \cap H^2 \cap \dots \cap H^m$$
$$\text{Reject at least one } H^j \Rightarrow \text{Reject } H$$

## Adaptive weighting (for intersections)

::::: columns
::: {.column width="50%"}
**Base TSM**: for $H^j$

$$S_{j,t} = \prod_{i = 1}^t s_{j, i}$$
:::

::: {.column width="50%"}
**Intersection TSM**: for $H$

$$S_t = \prod_{i = 1}^t \frac{\sum_j w_{j, i} \, s_{j, i}}{\sum_jw_{j, i}}$$
:::
:::::

. . .

The weights $w_{j, i}$ can depend on data up until time $i - 1$.

. . .

How to choose the weights $w_{j, i}$?

## Weighting schemes

![](images/progress.png)

::: footer
[Ek et al. (2023)](#references)
:::

## Scaling up

$k!$ alt-orders\
$\rightarrow$ :boom: explosion of decompositions & intersections

. . .

Use combinatorial optimisation methods.\
$\rightarrow$ see [tomorrow's
talk](https://virtual.oxfordabstracts.com/event/75429/submission/161)
:microphone:\
(Tue 11:30am, Experimental Design / Theory)

# Applications & challenges

## Where is sequential analysis used?

-   :ballot_box: Election auditing
-   :computer: A/B testing & online experimentation
-   :robot: Online decision-making
-   :microscope: Drug safety surveillance
-   :microbe: Public health surveillance
-   :dna: Clinical trials
-   :factory: Quality control
-   :credit_card: Fraud detection

## When to use anytime-valid methods

-   **Early decisions** are valuable
-   Data arrive **sequentially**
-   Analysis plans can evolve **flexibly**
-   Want **robustness** against "peeking"

## Research frontiers

Many open problems!

-   Improving efficiency ("power")
-   Complex, high-dimensional models
-   Regression/GLMs
-   Beyond iid/exchangeable data
-   Connections with Bayesian approaches

. . .

-   :desktop_computer: Software
-   :book: Teaching materials

## Conclusions

::::: columns
::: {.column width="50%"}
### What we used to teach

-   Peeking is dangerous
-   Fixed sample sizes are safe
-   Stick to the plan
:::

::: {.column width="50%"}
### What we now know

-   Peeking **can be safe**
-   Modern sequential methods give:
    -   anytime-valid inference
    -   flexibility
    -   robustness to unplanned analyses
:::
:::::

## Conclusions

Let’s modernise our statistical toolbox.

We can peek, we can adapt, and we can stay valid.

. . .

Time for **safe stats** :white_heart:, not statistical abstinence.

# Questions?

## References :books: {#references .smaller}

-   Ek, Stark, Stuckey, Vukcevic (2023). [Adaptively Weighted Audits of
    Instant-Runoff Voting Elections:
    AWAIRE](https://doi.org/10.1007/978-3-031-43756-4_3). In: Electronic
    Voting. E-Vote-ID 2023. *Lecture Notes in Computer Science* 14230:35--51.

-   Ramdas, Grünwald, Vovk, Shafer (2023). [Game-Theoretic Statistics and Safe
    Anytime-Valid Inference](https://doi.org/10.1214/23-STS894). *Statist.
    Sci.* 38(4):576--601.

-   Stark (2023). [ALPHA: Audit that learns from previously hand-audited
    ballots](https://doi.org/10.1214/22-AOAS1646). *Ann. Appl. Stat.*
    17(1):641--679.

-   Wald (1945). [Sequential tests of statistical
    hypotheses](https://doi.org/10.1214/aoms/1177731118). *Ann. Math. Stat.*
    16(2):117--186.

## Image sources :framed_picture: {.smaller}

The [coin flipping graphic](https://www.wannapik.com/vectors/3720) was designed
by Wannapik.

The following photographs were provided by the Australian Electoral Commission
and licensed under [CC BY
3.0](https://creativecommons.org/licenses/by/3.0/deed.en):

-   [ballot box
    opening](https://commons.wikimedia.org/wiki/File:AEC-HoR-election-night-opening.jpg)

-   [ballot
    counting](https://commons.wikimedia.org/wiki/File:AEC-HoR-counting-1.jpg)

-   [ballots in boxes at Centralised Senate
    Scrutiny](https://commons.wikimedia.org/wiki/File:AEC-Centralised-Senate-Scrutiny-papers-1.jpg)

The Higgins ballot paper (available from [The
Conversation](https://theconversation.com/what-us-election-officials-could-learn-from-australia-about-boosting-voter-turnout-128617))
was originally provided by [Hshook/Wikimedia
Commons](https://en.wikipedia.org/wiki/File:2016-ballot-paper-Higgins.png) and
is licensed under [CC BY-SA
4.0](https://creativecommons.org/licenses/by-sa/4.0/).

The [photograph of Abraham
Wald](https://en.wikipedia.org/wiki/File:Abraham_Wald_in_his_youth.jpg) is
freely available from Wikipedia.

The photograph of the [18th century
print](https://ark.digitalcommonwealth.org/ark:/50959/2z111h79p) is freely
available from the Digital Commonwealth; the original sits at the Boston Public
Library.

## Jokes :smile:

The "safe stats / abstinence" joke was borrowed from [Hadley
Wickham](https://nhorton.people.amherst.edu/mererenovation/17_Wickham.PDF).

# Appendix

## SPRT for binary data

```{r}
#| label: sprt-binary-redefine-variables
n <- 50
ns <- 1:n
```

::::: columns
::: {.column width="50%"}
```{r}
#| label: sprt-binary-example-statistic-with-bounds-again
#| fig-width: 5
#| fig-height: 4.5
#| out-width: "100%"

par(mar = c(4, 4, 1, 4))
plot(ns, s, type = "n", las = 1,
     xlim = c(0, n + 10),
     ylim = range(0, bounds),
     xlab = expression("Sample size, " * t),
     ylab = expression("Test statistic, " * S[t]))
grid()
lines(ns, s, lwd = 2, col = "blue")
abline(h = bounds, lty = 2, lwd = 1.5, col = "magenta")
points(tail(ns, 1), tail(s, 1), pch = 19, cex = 1.5, col = "blue")
axis(4, at = bounds, las = 1, col.axis = "magenta",
     expression(frac(beta, (1 - alpha)), frac((1 - beta), alpha)))
```
:::

::: {.column width="50%"}
```{r}
#| label: sprt-binary-example-proportion
#| fig-width: 5
#| fig-height: 4.5
#| out-width: "100%"

# SPRT decision boundary.
sprt_bound <- function(t, thresh) {
  A <- log(p1 / p0)
  B <- log((1 - p1) / (1 - p0))
  (log(thresh) / t - B) / (A - B)
}

# Draw plot.
ns10 <- 1:(n + 10)
par(mar = c(4, 5, 1, 2))
plot(ns, p.hat, type = "n", las = 1,
     xlim = c(0, n + 10),
     ylim = c(0, 1),
     xlab = expression("Sample size, " * t),
     ylab = expression("Sample proportion, " * Y[t] / t))
grid()
abline(h = c(p0, p1), lty = 3, lwd = 1.5, col = "black")
lines(ns10, sprt_bound(ns10, bounds[1]), col = "magenta", lty = 2, lwd = 1.5)
lines(ns10, sprt_bound(ns10, bounds[2]), col = "magenta", lty = 2, lwd = 1.5)
lines(ns, p.hat, lwd = 2, col = "blue")
points(tail(ns, 1), tail(p.hat, 1), pch = 19, cex = 1.5, col = "blue")
axis(4, c(p0, p1), expression(p[0], p[1]), las = 1)
```
:::
:::::

## Martingales: origin

<!-- https://ark.digitalcommonwealth.org/ark:/50959/2z111h79p -->

![](images/18_17_000138_image_access_800.jpg){fig-align="left"}

## Martingales: origin

"Martingales": :game_die: gambling strategies from 18th century France :clubs:

These strategies cannot "beat the house"

$\Rightarrow$ no guaranteed profit\
$\Rightarrow$ at best, a "fair" game

*Martingales* (in mathematics) represent the :moneybag: **wealth over time** of
a gambler playing a **fair game**.

## Tests based on martingales

Decision rule:

-   Reject $H_0$ if $S_t \geqslant 1 / \alpha$
-   Otherwise keep sampling (or give up)

Ville's inequality $\rightarrow$ **anytime-valid** type I error control

Growth rate under $H_1$ $\rightarrow$ statistical efficiency ("power")

## The SPRT is a martingale

-   At time $t$: $$\mathbb{E}_{H_0} \left(\frac{f_1(X_t)}{f_0(X_t)}\right)
      = \int \frac{f_1(x)}{f_0(x)} f_0(x) \, dx
      = \int f_1(x) \, dx = 1$$

-   Martingales generalise likelihood ratios.

## New concepts & terminology

-   **E-value**
-   E-variable
-   E-process
-   Anytime-valid p-values
-   **Confidence sequences** (anytime-valid confidence intervals)

## E-variable

-   A non-negative statistic $E$ with: $$\mathbb{E}_{H_0}(E) \leqslant 1$$
-   Betting analogy: payoff from a \$1 bet in a (sub-)fair game
-   Statistical interpretation: **evidence** against $H_0$
-   Large $E$ → strong evidence against $H_0$
-   A realisation of $E$ is an **e-value**.

## E-process

-   Similar to a supermartingale, but more general
-   Sequence $(E_t)$ with
    $$\mathbb{E}_{H_0}(E_t) \leqslant 1 \quad \text{for all } t.$$
-   Betting analogy: accumulated wealth after many fair bets
-   Statistical interpretation: **accumulated evidence** against $H_0$
-   Ville's inequality applies
-   Stop anytime → type I error control

## P-values from e-values

$$P_t = \frac{1}{E_t}$$

$$E_t > \frac{1}{\alpha}  \quad \Longleftrightarrow \quad  P_t < \alpha $$

-   $P_t$ is an *anytime-valid p-variable*.
-   A realisation of $P_t$ is an **anytime-valid p-value**.

## Confidence sequences {.smaller}

Fixed-sample hypothesis test $\longleftrightarrow$ confidence interval (CI)\
Sequential hypothesis test $\longleftrightarrow$ **confidence sequence** (CS)

```{r}
#| label: confidence-sequence-example-setup
# Based on examples from: https://doi.org/10.31234/osf.io/h5vae_v3
library(safestats)
set.seed(304)
xx <- rep(1:2, each = 40)
yy <- rnorm(xx, mean = 1.4 * xx)
design <- designSaviT(nPlan = c(40, 40), alpha = 0.05, testType = "twoSample")
result <- saviTTest(xx, yy, design, sequential = TRUE)
```

::::: columns
::: {.column width="50%"}
```{r}
#| label: confidence-sequence-example-plot1
#| fig-width: 6
#| fig-height: 5
#| out-width: "100%"
plot(result, xlab = "Sample size")
grid()
```
:::

::: {.column width="50%"}
```{r}
#| label: confidence-sequence-example-plot2
#| fig-width: 6
#| fig-height: 5
#| out-width: "100%"
plot(result, ylim = c(-5, 5), xlab = "Sample size", ylab = expression(theta),
     logScale = FALSE, wantConfSeqPlot = TRUE, h0Colour = "magenta")
grid()
```
:::
:::::

## "E-hacking"

Reanalysing the data with different test statistics ("betting strategies") and
only reporting the best one.

This is **not** safe stats.

Fundamental principle:

> Declare your bet before you play.

Pre-registration is still an important tool.

However, anytime-valid methods retain flexibility even after pre-specification.

## USA horror stories

-   2008: [Serious Error in Diebold Voting Software Caused Lost Ballots in
    California County](https://www.wired.com/2008/12/unique-election/)

-   2011: [Wisconsin Election Surprise: David Prosser Gains 7,500 Votes After
    ‘Human Error’ In Waukesha
    County](https://www.huffingtonpost.com.au/2011/04/07/david-prosser-wisconsin-supreme-court_n_846431.html)

-   2019: [Russians hacked 2 Florida voting
    systems](https://www.politico.com/states/florida/story/2019/05/14/russians-hacked-2-florida-voting-systems-fbi-and-desantis-refuse-to-release-details-1015772)

## Don't trust your scanner

[Xerox
bug](https://www.dkriesel.com/en/blog/2013/0802_xerox-workcentres_are_switching_written_numbers_when_scanning)
:bug::

::::: columns
::: {.column width="50%"}
![](https://www.dkriesel.com/_media/blog/2013/kostreg-vorher.png){fig-align="center"
width="80%"}
:::

::: {.column width="50%"}
![](https://www.dkriesel.com/_media/blog/2013/kostreg-nachher.png){fig-align="center"
width="80%"}
:::
:::::

::: footer
Source: <https://www.dkriesel.com/>
:::

## Prerequisites for an election audit

-   Trustworthy paper ballots
-   Ability to sample randomly from the ballots

## Audit outcomes

Possible decisions:

-   :trophy: **Certify** the reported election result
-   :hourglass: Request a **recount** of the votes

. . .

Consequences:

|                            |      Certify       |      Recount       |
|----------------------------|:------------------:|:------------------:|
| Reported result is wrong   |        :x:         | :white_check_mark: |
| Reported result is correct | :white_check_mark: |        :x:         |

## Audits as tests {.smaller}

|   | Reject $H_0$ (certify) | Do not reject $H_0$ (recount) |
|----|:--:|:--:|
| $H_0\colon$ Reported result is wrong | Type 1 error :x: | :white_check_mark: |
| $H_1\colon$ Reported result is correct | :white_check_mark: | Type 2 error :x: |

Type 1 error = Wrong democractic outcome

Type 2 error = Waste of resources (but no change of outcome)

## Australian voting systems :australia:

::::: columns
::: {.column width="50%"}
*Instant-runoff voting* (IRV)

-   Elects a **single** candidate
-   House of Representatives
-   Most state lower house elections
:::

::: {.column width="50%"}
*Single transferable vote* (STV)

-   Elects **multiple** candidates
-   Senate
-   Most state upper house elections
:::
:::::

## AWAIRE weighting schemes

How to choose the weights $w_{j, i}$?

Ideas:

-   **Largest**: Put weight 1 on the largest base TSM so far.
-   **Linear**: Proportional to previous value, $w_{j, i} = S_{j, i - 1}$.
-   **Quadratic**: Proportional to square of previous value,
    $w_{j, i} = S_{j, i - 1}^2$.
-   Many more...

Compared about 30 schemes. "Largest" was often the best.

## AWAIRE performance

![](images/awaire-results.png)

::: footer
[Ek et al. (2023)](#references)
:::
